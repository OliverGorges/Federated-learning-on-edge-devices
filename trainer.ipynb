{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Notebook for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils.Tensorflow.trainer import train_eval,  augmentData, prepareTFrecord\n",
    "import os\n",
    "from shutil import copy\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "import logging \n",
    "import requests\n",
    "import json\n",
    "from utils.Tensorflow.tff import sendData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split = 0\n",
    "save = False\n",
    "host = \"192.168.178.23:5000\"#\"3.120.138.160:5000\"\n",
    "\n",
    "def default(obj):\n",
    "    if type(obj).__module__ == numpy.__name__:\n",
    "        if isinstance(obj, numpy.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return obj.item()\n",
    "    else:\n",
    "        return obj.as_list()\n",
    "    raise TypeError('Unknown type:', type(obj))\n",
    "\n",
    "def callback(data):\n",
    "    logging.info(f'http://{host}/meta/{task[\"Key\"]} => {data}')\n",
    "    requests.post(f'http://{host}/meta/{task[\"Key\"]}', json=json.loads(json.dumps(data, default=default)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register Clients\n",
    "client = requests.get(f'http://{ host }/reg').json()\n",
    "if int(client['id']) == 0:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Data\n",
    "compData = os.path.join(\"Dataset\", \"data.zip\")\n",
    "result = requests.get(f'http://{ host }/data').json()\n",
    "print(result[\"filename\"][:-4])\n",
    "print(os.listdir(\"Dataset\"))\n",
    "if not result[\"filename\"][:-4] in os.listdir(\"Dataset\"):\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.download_file('federatedlearning-cg', f'data/{result[\"filename\"]}', compData)\n",
    "    with ZipFile(compData, 'r') as zipObj:\n",
    "        zipObj.extractall(\"Dataset\")\n",
    "\n",
    "    # remove compressed Data\n",
    "    os.remove(compData) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Wait for Trainphase    \n",
    "logging.info(f\"{time.time()}  {client['time']}\")\n",
    "while time.time() < client['time']:\n",
    "    time.sleep(5)\n",
    "    logging.info(client['time'] - time.time())\n",
    "\n",
    "task = requests.get(f'http://{ host }/task/{client[\"id\"]}').json()\n",
    "logging.info(task)\n",
    "# Check if Model exists\n",
    "\n",
    "if not task['Accepted']:\n",
    "    exit()\n",
    "\n",
    "taskname = task['Task']\n",
    "outDir = os.path.join(\"Traindata\", \"output\", taskname)\n",
    "data = task['Data']\n",
    "case = os.listdir(\"Dataset\")[0]\n",
    "imgDir = os.path.join(\"Dataset\", case, 'images')\n",
    "annoDir = os.path.join(\"Dataset\", case, \"annotations\")\n",
    "# Check Annotation format\n",
    "if os.listdir(annoDir)[0].endswith('.json'):\n",
    "    annoformat = \"JSON\"\n",
    "elif os.listdir(annoDir)[0].endswith('.xml'):\n",
    "    annoformat = \"XML\"\n",
    "\n",
    "data = task['Data']\n",
    "dataDir = os.path.join(\"Traindata\",\"data\")\n",
    "\n",
    "#Find Labelmap\n",
    "labelmap = None\n",
    "files = os.listdir(os.path.join(\"Dataset\", case))\n",
    "for f in files:\n",
    "    if f.startswith(\"label_map\"):\n",
    "        labelmap = os.path.join(\"Dataset\", case, f)\n",
    "        break\n",
    "\n",
    "if 'steps' in task:\n",
    "    steps = task['steps']\n",
    "else:\n",
    "    steps = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augImages, augAnnotations = augmentData(imgDir, annoDir, dataDir, split)\n",
    "\n",
    "result = os.path.join(\"Traindata\", \"output\", taskname)\n",
    "if not os.path.exists(result):\n",
    "        os.mkdir(result)\n",
    "tfrecordConfig = prepareTFrecord(augImages[0], augAnnotations[0], dataDir, labelmap=labelmap, annoFormat=annoformat, split=0.8)\n",
    "train_eval(result, dataDir, tfRecordsConfig=tfrecordConfig, model=task['ModelVersion'], steps=steps, eval_every_n_steps=200, _eval_callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = os.path.join(result, \"custom_pipeline.config\") \n",
    "meta = os.path.join(result, \"meta.json\")       \n",
    "logging.info(f'{result}, {pipeline}, {meta}')\n",
    "sendData(f'http://{host}/results/{client[\"id\"]}', result, pipeline, meta)\n",
    "\n",
    "print(result.text)"
   ]
  }
 ]
}